# @package _global_
task:
  name: softprompt
  info:
    name: unsupervised_paired
    # name: paired
    max_seq_length: 10000
    prepend_len: 3000
    max_tot_cn: 10
    max_tot_cn_arch: 10

  metrics:
    - reconstruction_loss_detail

  model_checkpoint: aracna/araCNA-models/pjflljt4/checkpoints/last.ckpt
  dataset:
    name: simmed_global
    n_batches: 1000 # because dataset is infinite, we need to specify how many batches to sample
    max_total: 10
    read_depth_range: [1, 110]
    read_depth_scale_range: [0.5, 0.5]
    baf_scale_range: [0.05, 0.05]


callbacks:
  model_checkpoint:
    monitor: val/read_recon


model:
  embeddings:
    name: "real_cna"
    input_dim: 2
    embed_dim: ${..d_model}
    chromosome_dim: 23 # N_CHROM
    token_dim: 24 # N CHROM + global, current approach just has seq/global but this allows for adding tokens in finetuning

  decoder:
    # name: 'paired'
    decoder_dim: ${..d_model}
    max_tot_cn: ${...task.info.max_tot_cn_arch}


trainer:
  max_epochs: 10000
  val_check_interval: 100 # every n bacthes


# scheduler:
